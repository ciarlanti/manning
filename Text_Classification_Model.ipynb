{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca61eba",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88e1877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,) (25000,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          5669632   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               197632    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,883,777\n",
      "Trainable params: 5,883,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(20000, 256) (20000,)\n",
      "(5000, 256) (5000,)\n",
      "Epoch 1/40\n",
      "40/40 [==============================] - 52s 1s/step - loss: 0.6197 - accuracy: 0.7255 - val_loss: 0.5500 - val_accuracy: 0.7614\n",
      "Epoch 2/40\n",
      "40/40 [==============================] - 50s 1s/step - loss: 0.5631 - accuracy: 0.7449 - val_loss: 0.5543 - val_accuracy: 0.7614\n",
      "Epoch 3/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.5248 - accuracy: 0.7434 - val_loss: 0.5858 - val_accuracy: 0.7442\n",
      "Epoch 4/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.4625 - accuracy: 0.7764 - val_loss: 0.6449 - val_accuracy: 0.6896\n",
      "Epoch 5/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.4116 - accuracy: 0.8125 - val_loss: 0.7218 - val_accuracy: 0.6704\n",
      "Epoch 6/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.3707 - accuracy: 0.8311 - val_loss: 0.7080 - val_accuracy: 0.6628\n",
      "Epoch 7/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.3560 - accuracy: 0.8412 - val_loss: 0.7386 - val_accuracy: 0.6754\n",
      "Epoch 8/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.3308 - accuracy: 0.8499 - val_loss: 0.7743 - val_accuracy: 0.6568\n",
      "Epoch 9/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.3213 - accuracy: 0.8523 - val_loss: 0.8034 - val_accuracy: 0.6728\n",
      "Epoch 10/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.3016 - accuracy: 0.8624 - val_loss: 0.8659 - val_accuracy: 0.6568\n",
      "Epoch 11/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.3052 - accuracy: 0.8544 - val_loss: 0.9158 - val_accuracy: 0.6650\n",
      "Epoch 12/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2934 - accuracy: 0.8608 - val_loss: 0.9187 - val_accuracy: 0.6714\n",
      "Epoch 13/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2812 - accuracy: 0.8612 - val_loss: 0.9405 - val_accuracy: 0.6926\n",
      "Epoch 14/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2752 - accuracy: 0.8647 - val_loss: 0.9819 - val_accuracy: 0.7076\n",
      "Epoch 15/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2715 - accuracy: 0.8642 - val_loss: 1.0275 - val_accuracy: 0.7222\n",
      "Epoch 16/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2680 - accuracy: 0.8604 - val_loss: 0.9950 - val_accuracy: 0.7024\n",
      "Epoch 17/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2736 - accuracy: 0.8607 - val_loss: 1.1370 - val_accuracy: 0.6968\n",
      "Epoch 18/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2623 - accuracy: 0.8650 - val_loss: 1.1699 - val_accuracy: 0.6944\n",
      "Epoch 19/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2552 - accuracy: 0.8672 - val_loss: 1.1080 - val_accuracy: 0.7092\n",
      "Epoch 20/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2584 - accuracy: 0.8636 - val_loss: 1.1530 - val_accuracy: 0.7130\n",
      "Epoch 21/40\n",
      "40/40 [==============================] - 50s 1s/step - loss: 0.2570 - accuracy: 0.8616 - val_loss: 1.2418 - val_accuracy: 0.7092\n",
      "Epoch 22/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2531 - accuracy: 0.8639 - val_loss: 1.2888 - val_accuracy: 0.7090\n",
      "Epoch 23/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2577 - accuracy: 0.8625 - val_loss: 1.2611 - val_accuracy: 0.6984\n",
      "Epoch 24/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2524 - accuracy: 0.8658 - val_loss: 1.2476 - val_accuracy: 0.7076\n",
      "Epoch 25/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2485 - accuracy: 0.8676 - val_loss: 1.3540 - val_accuracy: 0.7004\n",
      "Epoch 26/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2442 - accuracy: 0.8662 - val_loss: 1.2388 - val_accuracy: 0.7240\n",
      "Epoch 27/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2768 - accuracy: 0.8504 - val_loss: 1.3652 - val_accuracy: 0.6848\n",
      "Epoch 28/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2521 - accuracy: 0.8661 - val_loss: 1.2153 - val_accuracy: 0.7044\n",
      "Epoch 29/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2443 - accuracy: 0.8700 - val_loss: 1.5010 - val_accuracy: 0.7048\n",
      "Epoch 30/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2412 - accuracy: 0.8684 - val_loss: 1.4917 - val_accuracy: 0.7044\n",
      "Epoch 31/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2410 - accuracy: 0.8701 - val_loss: 1.4146 - val_accuracy: 0.6940\n",
      "Epoch 32/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2418 - accuracy: 0.8721 - val_loss: 1.5612 - val_accuracy: 0.7022\n",
      "Epoch 33/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2439 - accuracy: 0.8682 - val_loss: 1.4892 - val_accuracy: 0.6954\n",
      "Epoch 34/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2420 - accuracy: 0.8690 - val_loss: 1.6875 - val_accuracy: 0.6906\n",
      "Epoch 35/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2389 - accuracy: 0.8694 - val_loss: 1.5421 - val_accuracy: 0.6968\n",
      "Epoch 36/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2398 - accuracy: 0.8709 - val_loss: 1.6725 - val_accuracy: 0.6928\n",
      "Epoch 37/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2417 - accuracy: 0.8674 - val_loss: 1.7458 - val_accuracy: 0.6926\n",
      "Epoch 38/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2388 - accuracy: 0.8690 - val_loss: 1.5767 - val_accuracy: 0.6818\n",
      "Epoch 39/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2404 - accuracy: 0.8698 - val_loss: 1.7015 - val_accuracy: 0.6814\n",
      "Epoch 40/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.2380 - accuracy: 0.8724 - val_loss: 1.6856 - val_accuracy: 0.6936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.87      0.63     12500\n",
      "           1       0.44      0.11      0.17     12500\n",
      "\n",
      "    accuracy                           0.49     25000\n",
      "   macro avg       0.47      0.49      0.40     25000\n",
      "weighted avg       0.47      0.49      0.40     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from __future__ import absolute_import, division, print_function\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(\n",
    "    path='imdb.npz',\n",
    "    num_words=None,\n",
    "    skip_top=0,\n",
    "    maxlen=None,\n",
    "    seed=113,\n",
    "    start_char=1,\n",
    "    oov_char=2,\n",
    "    index_from=3\n",
    ")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "positive_sample_count = counts[1]\n",
    "idx = np.argwhere(y_train>0) # Select positive comment's index in training data\n",
    "np.random.seed(seed=100) # use seed to ensure selected records are always same\n",
    "np.random.shuffle(idx) #Shuffle it at random\n",
    "FRAC = 0.25\n",
    "idxs = idx[:int(len(idx)*FRAC)]\n",
    "y_trains = y_train[idxs]\n",
    "x_trains = x_train[idxs]\n",
    "idxn = np.argwhere(y_train==0)\n",
    "x_train0 = x_train[idxn]\n",
    "y_train0 = y_train[idxn]\n",
    "temp_idx = np.arange(0, len(idxs), 1)\n",
    "temp_idx_multi = np.tile(temp_idx, (1, 10)).T # shape is (31250, 1)\n",
    "np.random.seed(seed=200) # rerun from temp_idx_multi definition cell to ensure same result\n",
    "np.random.shuffle(temp_idx_multi)\n",
    "sample_idx = temp_idx_multi[:positive_sample_count].squeeze(1)\n",
    "x_train[sample_idx] # no point of using just the positive, since we are going by indeces anyway\n",
    "x_trains_os = x_train[sample_idx] # again, we are using indeces\n",
    "y_trains_os = y_train[sample_idx]\n",
    "x_train_assembled = np.concatenate((x_train0, x_trains_os), axis = None)\n",
    "y_train_assembled = np.concatenate((y_train0, y_trains_os), axis = None)\n",
    "shuffled_idx = np.arange(0, len(y_train_assembled), 1)\n",
    "np.random.seed(seed=300)\n",
    "np.random.shuffle(shuffled_idx)\n",
    "print(shuffled_idx.shape)\n",
    "shuffled_idx\n",
    "x_train_assembled_shuffled = x_train_assembled[shuffled_idx]\n",
    "y_train_assembled_shuffled = y_train_assembled[shuffled_idx]\n",
    "print(x_train_assembled_shuffled.shape, y_train_assembled_shuffled.shape)\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "index_word = dict([(value, key) for (key, value) in word_index.items()])\n",
    "def decode_review(encoded_array):\n",
    "    return ' '.join([index_word.get(i, '?') for i in encoded_array])\n",
    "train_data = tf.keras.preprocessing.sequence.pad_sequences(x_train_assembled_shuffled,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=256)\n",
    "test_data = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=256)\n",
    "vocab_size = len(word_index)\n",
    "MAX_SENTENCE_LENGTH=256\n",
    "EMBEDDING_SIZE=16\n",
    "HIDDEN_LAYER_SIZE=64\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "FRAC = 0.8 # fraction of training data used for training. Remaining is for cross validation.\n",
    "idx = np.arange(len(train_data))\n",
    "np.random.seed(seed=400)\n",
    "np.random.shuffle(idx)\n",
    "idxs = idx[:round(len(idx)*FRAC)] # Select random 80% for training data\n",
    "partial_x_train = train_data[idxs]\n",
    "partial_y_train = y_train_assembled[idxs]\n",
    "x_val = np.delete(train_data, idxs.tolist(), axis=0) # select remaining as cross validation data\n",
    "y_val = np.delete(y_train_assembled, idxs.tolist(), axis=0)\n",
    "print(partial_x_train.shape, partial_y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)\n",
    "predicted = model.predict(test_data)\n",
    "predicted\n",
    "predicted[predicted > 0.5] = 1\n",
    "predicted[predicted <= 0.5] = 0\n",
    "predictedf = predicted.flatten().astype(int)\n",
    "import pandas as pd\n",
    "df3 = pd.DataFrame(data=predictedf, columns=['predicted'])\n",
    "refdf = pd.DataFrame(data=y_test, columns=['actual'])\n",
    "y_actu = pd.Series(refdf['actual'], name='ACTUAL')\n",
    "y_pred = pd.Series(df3['predicted'], name='PREDICTED')\n",
    "predicted_results = y_pred.tolist()\n",
    "truth = y_actu.tolist()\n",
    "dl_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "dl_confusion\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(truth, predicted_results)\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
